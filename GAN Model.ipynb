{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/__init__.py:1467: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "from numpy import load\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import UpSampling2D\n",
    "from keras.layers import AveragePooling2D\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Layer\n",
    "from keras.layers import Add\n",
    "from keras.constraints import max_norm\n",
    "from keras.initializers import RandomNormal\n",
    "from keras import backend\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Personalized Layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weighted sum output\n",
    "class WeightedSum(Add):\n",
    "    # init with default value\n",
    "    def __init__(self, alpha=0.0, **kwargs):\n",
    "        super(WeightedSum, self).__init__(**kwargs)\n",
    "        self.alpha = backend.variable(alpha, name='ws_alpha')\n",
    " \n",
    "    # output a weighted sum of inputs\n",
    "    def _merge_function(self, inputs):\n",
    "        # only supports a weighted sum of two inputs\n",
    "        assert (len(inputs) == 2)\n",
    "        # ((1-a) * input1) + (a * input2)\n",
    "        output = ((1.0 - self.alpha) * inputs[0]) + (self.alpha * inputs[1])\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mini-batch standard deviation layer\n",
    "class MinibatchStdev(Layer):\n",
    "    # initialize the layer\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MinibatchStdev, self).__init__(**kwargs)\n",
    "\n",
    "    # perform the operation\n",
    "    def call(self, inputs):\n",
    "        # calculate the mean value for each pixel across channels\n",
    "        mean = backend.mean(inputs, axis=0, keepdims=True)\n",
    "        # calculate the squared differences between pixel values and mean\n",
    "        squ_diffs = backend.square(inputs - mean)\n",
    "        # calculate the average of the squared differences (variance)\n",
    "        mean_sq_diff = backend.mean(squ_diffs, axis=0, keepdims=True)\n",
    "        # add a small value to avoid a blow-up when we calculate stdev\n",
    "        mean_sq_diff += 1e-8\n",
    "        # square root of the variance (stdev)\n",
    "        stdev = backend.sqrt(mean_sq_diff)\n",
    "        # calculate the mean standard deviation across each pixel coord\n",
    "        mean_pix = backend.mean(stdev, keepdims=True)\n",
    "        # scale this up to be the size of one input feature map for each sample\n",
    "        shape = backend.shape(inputs)\n",
    "        output = backend.tile(mean_pix, (shape[0], shape[1], shape[2], 1))\n",
    "        # concatenate with the output\n",
    "        combined = backend.concatenate([inputs, output], axis=-1)\n",
    "        return combined\n",
    "\n",
    "    # define the output shape of the layer\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        # create a copy of the input shape as a list\n",
    "        input_shape = list(input_shape)\n",
    "        # add one to the channel dimension (assume channels-last)\n",
    "        input_shape[-1] += 1\n",
    "        # convert list to a tuple\n",
    "        return tuple(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pixel-wise feature vector normalization layer\n",
    "class PixelNormalization(Layer):\n",
    "    # initialize the layer\n",
    "    def __init__(self, **kwargs):\n",
    "        super(PixelNormalization, self).__init__(**kwargs)\n",
    "\n",
    "    # perform the operation\n",
    "    def call(self, inputs):\n",
    "        # calculate square pixel values\n",
    "        values = inputs**2.0\n",
    "        # calculate the mean pixel values\n",
    "        mean_values = backend.mean(values, axis=-1, keepdims=True)\n",
    "        # ensure the mean is not zero\n",
    "        mean_values += 1.0e-8\n",
    "        # calculate the sqrt of the mean squared value (L2 norm)\n",
    "        l2 = backend.sqrt(mean_values)\n",
    "        # normalize values by the l2 norm\n",
    "        normalized = inputs / l2\n",
    "        return normalized\n",
    "\n",
    "    # define the output shape of the layer\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definindo o discriminator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate wasserstein loss\n",
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return backend.mean(y_true * y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a discriminator block (no paper o total de filtros é diferente)\n",
    "def add_discriminator_block(old_model, n_input_layers=3):\n",
    "    # weight initialization\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    # weight constraint\n",
    "    const = max_norm(1.0)\n",
    "    # get shape of existing model\n",
    "    in_shape = list(old_model.input.shape)\n",
    "    # define new input shape as double the size\n",
    "    input_shape = (in_shape[-2].value*2, in_shape[-2].value*2, in_shape[-1].value)\n",
    "    in_image = Input(shape=input_shape)\n",
    "    # define new input processing layer\n",
    "    d = Conv2D(128, (1,1), padding='same', kernel_initializer=init, kernel_constraint=const)(in_image)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    # define new block\n",
    "    d = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    d = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    d = AveragePooling2D()(d)\n",
    "    block_new = d\n",
    "    # skip the input, 1x1 and activation for the old model\n",
    "    for i in range(n_input_layers, len(old_model.layers)):\n",
    "        d = old_model.layers[i](d)\n",
    "    # define straight-through model\n",
    "    model1 = Model(in_image, d)\n",
    "    # compile model\n",
    "    model1.compile(loss=wasserstein_loss, optimizer=Adam(lr=0.001, beta_1=0, beta_2=0.99, epsilon=10e-8))\n",
    "    # downsample the new larger image\n",
    "    downsample = AveragePooling2D()(in_image)\n",
    "    # connect old input processing to downsampled new input\n",
    "    block_old = old_model.layers[1](downsample)\n",
    "    block_old = old_model.layers[2](block_old)\n",
    "    # fade in output of old model input layer with new input\n",
    "    d = WeightedSum()([block_old, block_new])\n",
    "    # skip the input, 1x1 and activation for the old model\n",
    "    for i in range(n_input_layers, len(old_model.layers)):\n",
    "        d = old_model.layers[i](d)\n",
    "    # define straight-through model\n",
    "    model2 = Model(in_image, d)\n",
    "    # compile model\n",
    "    model2.compile(loss=wasserstein_loss, optimizer=Adam(lr=0.001, beta_1=0, beta_2=0.99, epsilon=10e-8))\n",
    "    return [model1, model2]\n",
    "\n",
    "# define the discriminator models for each image resolution\n",
    "def define_discriminator(n_blocks, input_shape=(4,4,3)):\n",
    "    # weight initialization\n",
    "    init = RandomNormal(stddev=0.02) # inicializacao é diferente da do paper\n",
    "    # weight constraint\n",
    "    const = max_norm(1.0)\n",
    "    model_list = list()\n",
    "    # base model input\n",
    "    in_image = Input(shape=input_shape)\n",
    "    # conv 1x1\n",
    "    d = Conv2D(128, (1,1), padding='same', kernel_initializer=init, kernel_constraint=const)(in_image)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    # conv 3x3 (output block)\n",
    "    d = MinibatchStdev()(d)\n",
    "    d = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    # conv 4x4\n",
    "    d = Conv2D(128, (4,4), padding='same', kernel_initializer=init, kernel_constraint=const)(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    # dense output layer\n",
    "    d = Flatten()(d)\n",
    "    out_class = Dense(1)(d)\n",
    "    # define model\n",
    "    model = Model(in_image, out_class)\n",
    "    # compile model\n",
    "    model.compile(loss=wasserstein_loss, optimizer=Adam(lr=0.001, beta_1=0, beta_2=0.99, epsilon=10e-8))\n",
    "    # store model\n",
    "    model_list.append([model, model])\n",
    "    # create submodels\n",
    "    for i in range(1, n_blocks):\n",
    "        # get prior model without the fade-on\n",
    "        old_model = model_list[i - 1][0]\n",
    "        # create new model for next resolution\n",
    "        models = add_discriminator_block(old_model)\n",
    "        # store model\n",
    "        model_list.append(models)\n",
    "    return model_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definindo o generator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a generator block\n",
    "def add_generator_block(old_model):\n",
    "    # weight initialization\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    # weight constraint\n",
    "    const = max_norm(1.0)\n",
    "    # get the end of the last block\n",
    "    block_end = old_model.layers[-2].output\n",
    "    # upsample, and define new block\n",
    "    upsampling = UpSampling2D()(block_end)\n",
    "    g = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(upsampling)\n",
    "    g = PixelNormalization()(g)\n",
    "    g = LeakyReLU(alpha=0.2)(g)\n",
    "    g = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(g)\n",
    "    g = PixelNormalization()(g)\n",
    "    g = LeakyReLU(alpha=0.2)(g)\n",
    "    # add new output layer\n",
    "    out_image = Conv2D(3, (1,1), padding='same', kernel_initializer=init, kernel_constraint=const)(g)\n",
    "    # define model\n",
    "    model1 = Model(old_model.input, out_image)\n",
    "    # get the output layer from old model\n",
    "    out_old = old_model.layers[-1]\n",
    "    # connect the upsampling to the old output layer\n",
    "    out_image2 = out_old(upsampling)\n",
    "    # define new output image as the weighted sum of the old and new models\n",
    "    merged = WeightedSum()([out_image2, out_image])\n",
    "    # define model\n",
    "    model2 = Model(old_model.input, merged)\n",
    "    return [model1, model2]\n",
    "\n",
    "# define generator models\n",
    "def define_generator(latent_dim, n_blocks, in_dim=4):\n",
    "    # weight initialization\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    # weight constraint\n",
    "    const = max_norm(1.0)\n",
    "    model_list = list()\n",
    "    # base model latent input\n",
    "    in_latent = Input(shape=(latent_dim,))\n",
    "    # linear scale up to activation maps\n",
    "    g  = Dense(128 * in_dim * in_dim, kernel_initializer=init, kernel_constraint=const)(in_latent)\n",
    "    g = Reshape((in_dim, in_dim, 128))(g)\n",
    "    # conv 4x4, input block\n",
    "    g = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(g)\n",
    "    g = PixelNormalization()(g)\n",
    "    g = LeakyReLU(alpha=0.2)(g)\n",
    "    # conv 3x3\n",
    "    g = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(g)\n",
    "    g = PixelNormalization()(g)\n",
    "    g = LeakyReLU(alpha=0.2)(g)\n",
    "    # conv 1x1, output block\n",
    "    out_image = Conv2D(3, (1,1), padding='same', kernel_initializer=init, kernel_constraint=const)(g)\n",
    "    # define model\n",
    "    model = Model(in_latent, out_image)\n",
    "    # store model\n",
    "    model_list.append([model, model])\n",
    "    # create submodels\n",
    "    for i in range(1, n_blocks):\n",
    "        # get prior model without the fade-on\n",
    "        old_model = model_list[i - 1][0]\n",
    "        # create new model for next resolution\n",
    "        models = add_generator_block(old_model)\n",
    "        # store model\n",
    "        model_list.append(models)\n",
    "    return model_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compose and train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "def load_real_samples(filename):\n",
    "    # load dataset\n",
    "    data = load(filename)\n",
    "    # extract numpy array\n",
    "    X = data['arr_0']\n",
    "    # convert from ints to floats\n",
    "    X = X.astype('float32')\n",
    "    # scale from [0,255] to [-1,1]\n",
    "    X = (X - 127.5) / 127.5\n",
    "    return X\n",
    "\n",
    "\n",
    "# select real samples\n",
    "def generate_real_samples(dataset, n_samples):\n",
    "    # choose random instances\n",
    "    ix = randint(0, dataset.shape[0], n_samples)\n",
    "    # select images\n",
    "    X = dataset[ix]\n",
    "    # generate class labels\n",
    "    y = ones((n_samples, 1))\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# generate points in latent space as input for the generator\n",
    "def generate_latent_points(latent_dim, n_samples):\n",
    "    # generate points in the latent space\n",
    "    x_input = randn(latent_dim * n_samples)\n",
    "    # reshape into a batch of inputs for the network\n",
    "    x_input = x_input.reshape(n_samples, latent_dim)\n",
    "    return x_input\n",
    "\n",
    "# use the generator to generate n fake examples, with class labels\n",
    "def generate_fake_samples(generator, latent_dim, n_samples):\n",
    "    # generate points in latent space\n",
    "    x_input = generate_latent_points(latent_dim, n_samples)\n",
    "    # predict outputs\n",
    "    X = generator.predict(x_input)\n",
    "    # create class labels\n",
    "    y = -ones((n_samples, 1))\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# This is a clumsy but effective approach to changing the alpha values. \n",
    "# Perhaps a cleaner implementation would involve a Keras Callback\n",
    "\n",
    "# update the alpha value on each instance of WeightedSum\n",
    "def update_fadein(models, step, n_steps):\n",
    "    # calculate current alpha (linear from 0 to 1)\n",
    "    alpha = step / float(n_steps - 1)\n",
    "    # update the alpha for each model\n",
    "    for model in models:\n",
    "        for layer in model.layers:\n",
    "            if isinstance(layer, WeightedSum):\n",
    "                backend.set_value(layer.alpha, alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define composite models for training generators via discriminators\n",
    "def define_composite(discriminators, generators):\n",
    "    model_list = list()\n",
    "    # create composite models\n",
    "    for i in range(len(discriminators)):\n",
    "        g_models, d_models = generators[i], discriminators[i]\n",
    "        # straight-through model\n",
    "        d_models[0].trainable = False\n",
    "        model1 = Sequential()\n",
    "        model1.add(g_models[0])\n",
    "        model1.add(d_models[0])\n",
    "        model1.compile(loss=wasserstein_loss, optimizer=Adam(lr=0.001, beta_1=0, beta_2=0.99, epsilon=10e-8))\n",
    "        # fade-in model\n",
    "        d_models[1].trainable = False\n",
    "        model2 = Sequential()\n",
    "        model2.add(g_models[1])\n",
    "        model2.add(d_models[1])\n",
    "        model2.compile(loss=wasserstein_loss, optimizer=Adam(lr=0.001, beta_1=0, beta_2=0.99, epsilon=10e-8))\n",
    "        # store\n",
    "        model_list.append([model1, model2])\n",
    "    return model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
